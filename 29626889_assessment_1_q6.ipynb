{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi class perceptron\n",
    "\n",
    "Assume we have N training examples {(x1,t1),...,(xN,tN)} where tn can get K discrete values {C1, ..., CK}, i.e. a K-class classification problem. We use ğ‘¦ğ‘› to represent the predicted label of ğ‘¥ğ‘› Model. To solve a K-class classification problem, we can learn K weight vectors wk, each of which corresponding to one of the classes. Prediction. In the prediction time, a data point x will be classified as argmaxk wk . x Training Algorithm. We train the multiclass perceptron based on the following\n",
    "algorithm:\n",
    "\n",
    "- Initialise the weight vectors randomly w1,..,wK\n",
    " * While not converged do:\n",
    " * For n = 1 to N do:\n",
    " * y=$argmax_k$ wk .xn\n",
    "    *Â If yn !=tn do\n",
    "    * ğ’˜ğ‘¦ğ‘›:=ğ’˜ğ‘¦ğ‘›âˆ’Î·ğ’™ğ‘›\n",
    "    * ğ’˜ğ‘¡ğ‘›:=ğ’˜ğ‘¡ğ‘›+Î·ğ’™ğ‘›\n",
    "\n",
    "In the section below, we implement a multi class perceptron with gradient descent of mini batches of size 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we load the data and libraries required to implement the perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'ggplot2' was built under R version 3.6.1\""
     ]
    }
   ],
   "source": [
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train<-read.csv('Task1D_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test<-read.csv('Task1D_test.csv')\n",
    "test.data = test[,1:4]\n",
    "test.label = test[,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_test<- as.matrix(cbind(1, test.data)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary function to perform predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val<-function(Phi,W1,W2,W3)\n",
    "{\n",
    "     V1<-Phi%*%W1[1,]\n",
    "    V2<-Phi%*%W2[1,]\n",
    "    V3<-Phi%*%W3[1,]\n",
    "    df<-data.frame('C1'=V1, 'C2'=V2, 'C3'=V3)\n",
    "    output<-colnames(df)[apply(df,1,which.max)]\n",
    "    return(output)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we code the multi class perceptron and the comments to describe how everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123) # to make the output reproducible\n",
    "error_df <- data.frame() # dataframe to store errors\n",
    "batch = 1 # variable to store batch number\n",
    "for(index in seq(5,nrow(train),by=5)) # to create mini batches\n",
    "{\n",
    "    ind <- 1:index # we split the data based on 5 batches\n",
    "    train.data = train[ind,1:4]\n",
    "    train.label = train[ind,5]\n",
    "    Phi <- as.matrix(cbind(1, train.data)) \n",
    "    tau <- 1 # Iteration counter\n",
    "    eta <- 0.09# Learning rate\n",
    "    epsilon <- 0.001 # Stoping criterion\n",
    "    tau.max <- 100000 # Maximum number of iterations\n",
    "    W1<- matrix(,nrow=tau.max, ncol=ncol(Phi)) # Empty Weight vector for class 1 \n",
    "    W1[1,] <- runif(ncol(Phi)) # Random initial values for weight vector for class 1\n",
    "    W2 <- matrix(,nrow=tau.max, ncol=ncol(Phi))  # Empty Weight vector for class 2 \n",
    "    W2[1,] <- runif(ncol(Phi)) # Random initial values for weight vector for class 2\n",
    "    W3 <- matrix(,nrow=tau.max, ncol=ncol(Phi))# Empty Weight vector for class 3\n",
    "    W3[1,] <- runif(ncol(Phi)) # Random initial values for weight vector for class 3\n",
    "    V1<-Phi%*%W1[1,] # V1,V2 and V3 stores the class labels for C1, C2 and C3\n",
    "    V2<-Phi%*%W2[1,]\n",
    "    V3<-Phi%*%W3[1,]\n",
    "    df<-data.frame('C1'=V1, 'C2'=V2, 'C3'=V3) # dataframe to store the class labels\n",
    "    output<-colnames(df)[apply(df,1,which.max)] # Tells us which is the class label assigned by the algorithm\n",
    "    train.len= nrow(train.data) # length of train data\n",
    "    terminate<-FALSE\n",
    "    while(!terminate) # while the perceptron doesn't converge\n",
    "    {\n",
    "        terminate <- tau >= tau.max| ((sum(pred_val(Phi,W1,W2,W3)!=train.label)/train.len) <= epsilon) # terminate condition(if number of iteration increases or the misclassification rate falls below the threshold)\n",
    "        for(j in seq(5,train.len,by = 5)) # for loop to execute in a batch of size 5\n",
    "        {   \n",
    "            train.index <- sample(1:j, replace = FALSE) # samples the indeces in batches of 5 without replacement so that the data is used entirely.\n",
    "            Phi_i <- Phi[train.index,] # creates a new phi with the sample and the same with train labels.\n",
    "            T <- train.label[train.index]\n",
    "            output<-pred_val(Phi_i,W1,W2,W3) # predict the labels\n",
    "        \n",
    "            for (i in 1:5) # performs comparison in batches of 5\n",
    "            {\n",
    "       \n",
    "      \n",
    "            if (tau == tau.max) {break} # if converged, break\n",
    "            \n",
    "            \n",
    "            if(T[i]!= output[i]) # if the predicted label is not equal to class label\n",
    "            {\n",
    "                    \n",
    "                    # update the weights for each of the classes for misclassification.\n",
    "                if(T[i]=='C1')\n",
    "                    \n",
    "                    {\n",
    "                    \n",
    "                    W1[1,] <- W1[1,] + eta * Phi_i[i,] \n",
    "                    \n",
    "                    }\n",
    "                else if (T[i]=='C2')\n",
    "                    {\n",
    "                    \n",
    "                    W2[1,] <- W2[1,] + eta * Phi_i[i,] \n",
    "                    \n",
    "                    }\n",
    "                else \n",
    "                    {\n",
    "                   \n",
    "                    W3[1,] <- W3[1,] + eta * Phi_i[i,] \n",
    "                   \n",
    "                    }\n",
    "                if(output[i]=='C1') # if the predicted label matches the class label\n",
    "                    {\n",
    "                    # update the weights for the right class labels.   \n",
    "                    W1[1,] <- W1[1,] - eta * Phi_i[i,]\n",
    "                    }\n",
    "                else if (output[i]=='C2')\n",
    "                    {\n",
    "                    \n",
    "                    W2[1,] <- W2[1,] - eta * Phi_i[i,] \n",
    "                    \n",
    "                    }\n",
    "                else \n",
    "                    {\n",
    "                   \n",
    "                    W3[1,] <- W3[1,] - eta * Phi_i[i,] \n",
    "                    \n",
    "                    }\n",
    "             }\n",
    "            tau <- tau + 1 # increment the iteration by 1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    error_df[batch,'Error'] <- (sum(pred_val(Phi_test,W1,W2,W3)!=test.label)/nrow(test.data)) # stores the error as each batch gets executed\n",
    "    error_df[batch, 'Batch_num'] <- batch\n",
    "    batch = batch + 1\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we generate a plot showing the error rate as the number of batch increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAOVBMVEUAAAAAAP8zMzNNTU1o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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(error_df,aes(x=Batch_num,y=Error))+geom_line(color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, we can interpret that as the batch numbers increase, the test error decreases. The error starts decreases usualy around batch numbers which are multiples of 5(for example around batch number 5 and 10) after which they stabilize and then decreases again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
